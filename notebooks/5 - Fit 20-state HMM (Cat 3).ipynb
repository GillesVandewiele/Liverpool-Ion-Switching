{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the result from previous notebook\n",
    "train = pd.read_csv('../data/train_2.csv')\n",
    "test = pd.read_csv('../data/test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000 900000\n"
     ]
    }
   ],
   "source": [
    "BATCHES = np.array([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 70])\n",
    "CATEGORIES = np.array([1, 1, 2, 3, 5, 4, 2, 3, 4, 5, 6, 3, 4, 6, 2, 5, 4, 5, 6, 3, 6, 6])\n",
    "\n",
    "# I would not advice CATEGORY > 3 with hmmlearn... (will take a LONG time)\n",
    "CATEGORY = 3\n",
    "\n",
    "signal = np.concatenate((train['signal'].values, test['signal'].values))\n",
    "\n",
    "ix = np.where(CATEGORIES == CATEGORY)[0]\n",
    "starts = BATCHES[ix]\n",
    "ends = BATCHES[ix + 1]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for start, end in zip(starts, ends):\n",
    "    subsignal = signal[start*100_000:end*100_000]\n",
    "    if start < 50:\n",
    "        subchannels = train['open_channels'].values[start*100_000:end*100_000]\n",
    "    else:\n",
    "        subchannels = [-1]*((end-start)*100_000)\n",
    "        \n",
    "    if start == 35:\n",
    "        subsignal = list(subsignal[:100000]) + list(subsignal[-100000:])\n",
    "        subchannels = list(subchannels[:100000]) + list(subchannels[-100000:])\n",
    "    \n",
    "    X.extend(subsignal)\n",
    "    y.extend(subchannels)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix shape: (20, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -501940.5201             +nan\n",
      "         2     -490739.9518      +11200.5683\n",
      "         3     -490293.7547        +446.1971\n",
      "         4     -490141.4750        +152.2797\n",
      "         5     -490070.0501         +71.4249\n",
      "         6     -490031.7036         +38.3465\n",
      "         7     -490009.3388         +22.3648\n",
      "         8     -489995.4640         +13.8748\n",
      "         9     -489986.3995          +9.0645\n",
      "        10     -489980.1955          +6.2039\n",
      "        11     -489975.7609          +4.4346\n",
      "        12     -489972.4581          +3.3028\n",
      "        13     -489969.9012          +2.5569\n",
      "        14     -489967.8491          +2.0520\n",
      "        15     -489966.1469          +1.7022\n",
      "        16     -489964.6919          +1.4550\n",
      "        17     -489963.4147          +1.2772\n",
      "        18     -489962.2683          +1.1463\n",
      "        19     -489961.2228          +1.0455\n",
      "        20     -489960.2611          +0.9617\n"
     ]
    }
   ],
   "source": [
    "# Estimate the transition matrix based on the ground truth\n",
    "Ptran = np.array([[0     , 0.0067, 0     , 0     ],\n",
    "                  [0.0373, 0     , 0.2762, 0.0230],\n",
    "                  [0     , 0.1991, 0     , 0     ],\n",
    "                  [0     , 0.0050, 0     , 0     ]])\n",
    "States = [1, 1, 0, 0]\n",
    "\n",
    "def calculate_matrix(transition_matrix, states, number_processes):\n",
    "    \"\"\"\n",
    "    Expand a transition matrix to model separate processes.\n",
    "    If max(open_channels) = K, then we assume K 0/1 processes. \n",
    "    E.g. our data category 3 corresponds to a maximum\n",
    "    of 3 open_channels, so 3 processes.\n",
    "    \n",
    "    We create model a combination_with_repetition(3, 4) = 20\n",
    "    transition matrix. The first row & col corresponds to all\n",
    "    processes being in the first hidden state (1, 1, 1). The\n",
    "    second row & col corresponds to (1, 1, 2), and so on until\n",
    "    (4, 4, 4).\n",
    "    \n",
    "    To calculate the transition probability from (1, 2, 2) to\n",
    "    (1, 1, 3), we calculate P(1->1) * P(2->1) * P(2->3). But\n",
    "    also for all permutations (e.g. (2, 1, 2) and (3, 1, 1)).\n",
    "    In the end, we normalize our transition matrix.\n",
    "    \"\"\"\n",
    "    # Fill in diagonals such that each row sums to 1\n",
    "    for i in range(transition_matrix.shape[0]):\n",
    "        transition_matrix[i, i] = 1 - np.sum(transition_matrix[i, :])\n",
    "\n",
    "    n0 = len(states)\n",
    "    new_transition_matrix = transition_matrix.copy()\n",
    "    new_states = [(x,) for x in range(n0)]\n",
    "    for process in range(1, number_processes):\n",
    "        # We expand our current transition matrix (that models up to `process` number\n",
    "        # of separate processes) its' dimensions by n0. We basically add another\n",
    "        # possible state transition for a new process.\n",
    "        nc = new_transition_matrix.shape[0]\n",
    "        temp_transition_matrix = np.zeros((n0*nc, n0*nc))\n",
    "        temp_states = []\n",
    "        for i in range(n0):\n",
    "            temp_states.extend([s + (i,) for s in new_states])\n",
    "            for j in range(n0):\n",
    "                # We add i -> j as our final transition\n",
    "                temp_transition_matrix[i*nc:(i+1)*nc, j*nc:(j+1)*nc] = transition_matrix[i][j] * new_transition_matrix\n",
    "              \n",
    "        # We now group similar processes together to reduce our matrix. \n",
    "        # E.g. (1, 2, 3) is the same as (2, 3, 1)\n",
    "        new_states = sorted(list(set([tuple(sorted(x)) for x in temp_states])))\n",
    "        new_transition_matrix = np.zeros((len(new_states), len(new_states)))\n",
    "        for i in range(len(new_states)):\n",
    "            ix_i = [k for k, x in enumerate(temp_states) if tuple(sorted(x)) == new_states[i]]\n",
    "            for j in range(len(new_states)):\n",
    "                ix_j = [k for k, x in enumerate(temp_states) if tuple(sorted(x)) == new_states[j]]\n",
    "                new_transition_matrix[i, j] = np.sum(temp_transition_matrix[ix_i, :][:, ix_j])\n",
    "                new_transition_matrix[i, j] /= len(ix_i)\n",
    "    \n",
    "    new_channels = []\n",
    "    for s in new_states:\n",
    "        new_channels.append(sum([states[x] for x in s]))\n",
    "    new_channels= np.array(new_channels)\n",
    "        \n",
    "    return new_transition_matrix, new_channels\n",
    "\n",
    "Ptran, States = calculate_matrix(Ptran, States, 3)\n",
    "print('Transition matrix shape: {}'.format(Ptran.shape))\n",
    "\n",
    "# Estimate means and covs per unique ground truth value\n",
    "means = []\n",
    "covs = []\n",
    "for c in sorted(np.unique(y[y >= 0])):\n",
    "    means.append(np.mean(X[y == c]))\n",
    "    covs.append(np.cov(X[y == c]))\n",
    "    \n",
    "means = [means[c] for c in States]\n",
    "covs = [covs[c] for c in States]\n",
    "    \n",
    "# Defining our HMM\n",
    "hmm = GaussianHMM(\n",
    "    n_components=len(States),           # Number of hidden states\n",
    "    n_iter=50,                          # Total number of iterations\n",
    "    verbose=True,                       # Show logs\n",
    "    algorithm='map',                    # Use maximum a posteriori instead of Viterbi\n",
    "    params='stmc',                      # Optimize start probs, transmat, means, covs\n",
    "    random_state=42,\n",
    "    init_params='s',                    # Manually initialize all but start probabilities\n",
    "    covariance_type='full',             # Separate covariance per hidden state\n",
    "    tol=1                               # Convergence criterion (set high for fast execution)\n",
    ")\n",
    "\n",
    "# Initialize the parameters of our HMM\n",
    "hmm.n_features = 1\n",
    "hmm.means_ = np.array(means).reshape(-1 ,1)\n",
    "hmm.covars_ = np.array(covs).reshape(-1, 1, 1)\n",
    "hmm.transmat_ = Ptran\n",
    "\n",
    "# Fit our HMM (this takes a while)\n",
    "_ = hmm.fit(X.reshape(-1, 1), lengths=[100000]*(len(X) // 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866748988341756\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "preds = np.array(States)[hmm.predict(X.reshape(-1, 1), lengths=[100000]*(len(X) // 100000))]\n",
    "\n",
    "# Our naive HMM\n",
    "print(f1_score(y[y >= 0], preds[y >= 0], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
