{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the result from previous notebook\n",
    "train = pd.read_csv('../data/train_2.csv')\n",
    "test = pd.read_csv('../data/test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000 900000\n"
     ]
    }
   ],
   "source": [
    "BATCHES = np.array([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 70])\n",
    "CATEGORIES = np.array([1, 1, 2, 3, 5, 4, 2, 3, 4, 5, 6, 3, 4, 6, 2, 5, 4, 5, 6, 3, 6, 6])\n",
    "CATEGORY = 3\n",
    "\n",
    "signal = np.concatenate((train['signal'].values, test['signal'].values))\n",
    "\n",
    "ix = np.where(CATEGORIES == CATEGORY)[0]\n",
    "starts = BATCHES[ix]\n",
    "ends = BATCHES[ix + 1]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for start, end in zip(starts, ends):\n",
    "    subsignal = signal[start*100_000:end*100_000]\n",
    "    if start < 50:\n",
    "        subchannels = train['open_channels'].values[start*100_000:end*100_000]\n",
    "    else:\n",
    "        subchannels = [-1]*((end-start)*100_000)\n",
    "        \n",
    "    if start == 35:\n",
    "        subsignal = list(subsignal[:100000]) + list(subsignal[-100000:])\n",
    "        subchannels = list(subchannels[:100000]) + list(subchannels[-100000:])\n",
    "    \n",
    "    X.extend(subsignal)\n",
    "    y.extend(subchannels)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(Psig, Ptran, etat_in=None, coef=1, normalize=True):\n",
    "    if etat_in is None: etat_in = np.ones(Psig.shape)/Psig.shape[1]\n",
    "    alpha = np.zeros(Psig.shape) # len(sig) x n_state\n",
    "    etat = np.zeros(Psig.shape) # len(sig) x n_state\n",
    "    C = np.zeros(Psig.shape[0]) # scale vector for each timestep\n",
    "    \n",
    "    etat[0] = etat_in[0]\n",
    "    alpha[0] = etat_in[0]\n",
    "    if normalize: \n",
    "        alpha[0] = etat_in[0]*Psig[0]\n",
    "        alpha[0]/=alpha[0].sum()\n",
    "\n",
    "    for j in range(1, Psig.shape[0]):\n",
    "        etat[j] = alpha[j-1]@Ptran\n",
    "        if normalize: etat[j] /= etat[j].sum()\n",
    "        etat[j] = (etat[j]**coef) * ((etat_in[j])**(1-coef))\n",
    "        if normalize: etat[j] /= etat[j].sum()\n",
    "        alpha[j] = etat[j]  * Psig[j]\n",
    "        alpha[j] /= alpha[j].sum()\n",
    "    return alpha, etat\n",
    "\n",
    "def calculate_matrix(transition_matrix, states, number_processes):\n",
    "    \"\"\"\n",
    "    Expand a transition matrix to model separate processes.\n",
    "    If max(open_channels) = K, then we assume K 0/1 processes. \n",
    "    E.g. our data category 3 corresponds to a maximum\n",
    "    of 3 open_channels, so 3 processes.\n",
    "    \n",
    "    We create model a combination_with_repetition(3, 4) = 20\n",
    "    transition matrix. The first row & col corresponds to all\n",
    "    processes being in the first hidden state (1, 1, 1). The\n",
    "    second row & col corresponds to (1, 1, 2), and so on until\n",
    "    (4, 4, 4).\n",
    "    \n",
    "    To calculate the transition probability from (1, 2, 2) to\n",
    "    (1, 1, 3), we calculate P(1->1) * P(2->1) * P(2->3). But\n",
    "    also for all permutations (e.g. (2, 1, 2) and (3, 1, 1)).\n",
    "    In the end, we normalize our transition matrix.\n",
    "    \"\"\"\n",
    "    # Fill in diagonals such that each row sums to 1\n",
    "    for i in range(transition_matrix.shape[0]):\n",
    "        transition_matrix[i, i] = 1 - np.sum(transition_matrix[i, :])\n",
    "\n",
    "    n0 = len(states)\n",
    "    new_transition_matrix = transition_matrix.copy()\n",
    "    new_states = [(x,) for x in range(n0)]\n",
    "    for process in range(1, number_processes):\n",
    "        # We expand our current transition matrix (that models up to `process` number\n",
    "        # of separate processes) its' dimensions by n0. We basically add another\n",
    "        # possible state transition for a new process.\n",
    "        nc = new_transition_matrix.shape[0]\n",
    "        temp_transition_matrix = np.zeros((n0*nc, n0*nc))\n",
    "        temp_states = []\n",
    "        for i in range(n0):\n",
    "            temp_states.extend([s + (i,) for s in new_states])\n",
    "            for j in range(n0):\n",
    "                # We add i -> j as our final transition\n",
    "                temp_transition_matrix[i*nc:(i+1)*nc, j*nc:(j+1)*nc] = transition_matrix[i][j] * new_transition_matrix\n",
    "              \n",
    "        # We now group similar processes together to reduce our matrix. \n",
    "        # E.g. (1, 2, 3) is the same as (2, 3, 1)\n",
    "        new_states = sorted(list(set([tuple(sorted(x)) for x in temp_states])))\n",
    "        new_transition_matrix = np.zeros((len(new_states), len(new_states)))\n",
    "        for i in range(len(new_states)):\n",
    "            ix_i = [k for k, x in enumerate(temp_states) if tuple(sorted(x)) == new_states[i]]\n",
    "            for j in range(len(new_states)):\n",
    "                ix_j = [k for k, x in enumerate(temp_states) if tuple(sorted(x)) == new_states[j]]\n",
    "                new_transition_matrix[i, j] = np.sum(temp_transition_matrix[ix_i, :][:, ix_j])\n",
    "                new_transition_matrix[i, j] /= len(ix_i)\n",
    "    \n",
    "    new_channels = []\n",
    "    for s in new_states:\n",
    "        new_channels.append(sum([states[x] for x in s]))\n",
    "    new_channels= np.array(new_channels)\n",
    "        \n",
    "    return new_transition_matrix, new_channels\n",
    "\n",
    "def get_Psig(signal, States, kexp):\n",
    "    Psig = np.zeros((len(signal), len(States)))\n",
    "    for i in range(len(Psig)):\n",
    "        Psig[i] = np.exp((-(signal[i] - States)**2)/(kexp))\n",
    "    return Psig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix shape: (20, 20)\n"
     ]
    }
   ],
   "source": [
    "Ptran = np.array([[0     , 0.0067, 0     , 0     ],\n",
    "                  [0.0373, 0     , 0.2762, 0.0230],\n",
    "                  [0     , 0.1991, 0     , 0     ],\n",
    "                  [0     , 0.0050, 0     , 0     ]])\n",
    "States = [1, 1, 0, 0]\n",
    "\n",
    "Ptran, States = calculate_matrix(Ptran, States, 3)\n",
    "print('Transition matrix shape: {}'.format(Ptran.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These hyper-parameters can be tuned in a supervised manner with macro-F1 (which works best\n",
    "# for a competition), but also in an unsupervised manner using, for example, likelihood.\n",
    "Kexp = .1307\n",
    "Kexpp = 1.8\n",
    "COEF_BACK = .9192\n",
    "COEF_FOR = .8869\n",
    "COEF_FIN = 0.50\n",
    "COEF_FIN3 = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max/min 2.999999999924185 4.73579276123209e-09\n",
      "Max/min 2.9999999999806106 2.8490946323121153e-09\n",
      "Max/min 2.999999999937666 5.147520748358743e-09\n",
      "Max/min 2.9999999999242286 8.617654375472815e-09\n",
      "Max/min 2.999999999996627 3.1780437095570796e-09\n",
      "Max/min 2.9999999999867057 1.3924418429139992e-09\n",
      "Max/min 2.9999999999956555 5.215197487300455e-10\n",
      "Max/min 2.9999999999999996 4.306866578467323e-09\n",
      "Max/min 2.999999999993938 9.61203510709536e-09\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(len(X))\n",
    "for k in range(len(X) // 100000):\n",
    "    sig = X[100000*k:100000*(k + 1)]\n",
    "    nstates = Ptran.shape[0]\n",
    "    Psig = get_Psig(sig, States, Kexp)\n",
    "    \n",
    "    alpha0, etat0 = forward(Psig, Ptran, normalize=False)\n",
    "    alpha1, etat1 = forward(Psig[::-1], np.transpose(Ptran), etat_in=etat0[::-1], coef=COEF_BACK)\n",
    "    alpha2, etat2 = forward(Psig, Ptran, etat_in=etat1[::-1], coef=COEF_FOR)\n",
    "\n",
    "    alpha3 = etat1[::-1]*etat2*Psig**Kexpp\n",
    "    for j, alp in enumerate(alpha3): alpha3[j] /= alp.sum()\n",
    "\n",
    "    pred = COEF_FIN*(alpha1[::-1]) + (1-COEF_FIN-COEF_FIN3)*alpha2 + COEF_FIN3*alpha3\n",
    "\n",
    "    preds[100000*k:100000*(k + 1)] = pred@States\n",
    "    print('Max/min', (pred@States).max(), (pred@States).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986794704167445\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y[y >= 0], np.round(preds[y >= 0]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/cat3_preds.npy', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
